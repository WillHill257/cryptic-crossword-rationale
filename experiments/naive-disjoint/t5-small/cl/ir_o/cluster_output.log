10/17/2022 08:44:14 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False
10/17/2022 08:44:14 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=../experiments/runs/Oct17_08-44-13_mscluster28.ms.wits.ac.za,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=3.0,
optim=adamw_hf,
output_dir=../experiments/naive-disjoint/t5-small/cl/ir_o,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=True,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=../experiments/,
save_on_each_node=False,
save_steps=5000,
save_strategy=steps,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_ipex=False,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
10/17/2022 08:44:15 - WARNING - datasets.builder - Using custom data configuration default-26cae9c466703ff2
10/17/2022 08:44:15 - INFO - datasets.builder - Generating dataset json (./models/cache/json/default-26cae9c466703ff2/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)
Downloading and preparing dataset json/default to ./models/cache/json/default-26cae9c466703ff2/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253...
10/17/2022 08:44:15 - INFO - datasets.download.download_manager - Downloading took 0.0 min
10/17/2022 08:44:17 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min
10/17/2022 08:44:17 - INFO - datasets.utils.info_utils - Unable to verify checksums.
10/17/2022 08:44:17 - INFO - datasets.builder - Generating train split
10/17/2022 08:44:18 - INFO - datasets.builder - Generating validation split
10/17/2022 08:44:19 - INFO - datasets.builder - Generating test split
10/17/2022 08:44:20 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.
Dataset json downloaded and prepared to ./models/cache/json/default-26cae9c466703ff2/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253. Subsequent calls will reuse this data.
10/17/2022 08:44:20 - INFO - __main__ - Loaded the naive-disjoint dataset:
DatasetDict({
    train: Dataset({
        features: ['clue', 'answer', 'annotation', 'predicted_rationale', 'predicted_answer'],
        num_rows: 353630
    })
    validation: Dataset({
        features: ['clue', 'answer', 'annotation', 'predicted_rationale', 'predicted_answer'],
        num_rows: 119828
    })
    test: Dataset({
        features: ['clue', 'answer', 'annotation', 'predicted_rationale', 'predicted_answer'],
        num_rows: 118751
    })
})
This is for an IR->O model based on t5-small
{'loss': 4.4477, 'learning_rate': 4.981148010738093e-05, 'epoch': 0.01}
{'loss': 3.8655, 'learning_rate': 4.962296021476186e-05, 'epoch': 0.02}
{'loss': 3.7997, 'learning_rate': 4.9434440322142796e-05, 'epoch': 0.03}
{'loss': 3.7322, 'learning_rate': 4.924592042952372e-05, 'epoch': 0.05}
{'loss': 3.71, 'learning_rate': 4.905740053690466e-05, 'epoch': 0.06}
{'loss': 3.6264, 'learning_rate': 4.8868880644285583e-05, 'epoch': 0.07}
{'loss': 3.6133, 'learning_rate': 4.8680360751666524e-05, 'epoch': 0.08}
{'loss': 3.5917, 'learning_rate': 4.849184085904745e-05, 'epoch': 0.09}
{'loss': 3.5847, 'learning_rate': 4.830332096642838e-05, 'epoch': 0.1}
{'loss': 3.5704, 'learning_rate': 4.811480107380931e-05, 'epoch': 0.11}
{'loss': 3.536, 'learning_rate': 4.7926281181190244e-05, 'epoch': 0.12}
{'loss': 3.5213, 'learning_rate': 4.773776128857117e-05, 'epoch': 0.14}
{'loss': 3.4898, 'learning_rate': 4.7549241395952105e-05, 'epoch': 0.15}
{'loss': 3.4757, 'learning_rate': 4.736072150333303e-05, 'epoch': 0.16}
{'loss': 3.4627, 'learning_rate': 4.7172201610713965e-05, 'epoch': 0.17}
{'loss': 3.4364, 'learning_rate': 4.69836817180949e-05, 'epoch': 0.18}
{'loss': 3.4176, 'learning_rate': 4.6795161825475825e-05, 'epoch': 0.19}
{'loss': 3.4352, 'learning_rate': 4.660664193285676e-05, 'epoch': 0.2}
{'loss': 3.4162, 'learning_rate': 4.6418122040237686e-05, 'epoch': 0.21}
{'loss': 3.3745, 'learning_rate': 4.622960214761862e-05, 'epoch': 0.23}
{'loss': 3.3835, 'learning_rate': 4.604108225499955e-05, 'epoch': 0.24}
{'loss': 3.3744, 'learning_rate': 4.585256236238048e-05, 'epoch': 0.25}
{'loss': 3.3749, 'learning_rate': 4.5664042469761406e-05, 'epoch': 0.26}
{'loss': 3.382, 'learning_rate': 4.547552257714234e-05, 'epoch': 0.27}
{'loss': 3.3503, 'learning_rate': 4.5287002684523273e-05, 'epoch': 0.28}
{'loss': 3.3234, 'learning_rate': 4.509848279190421e-05, 'epoch': 0.29}
{'loss': 3.3063, 'learning_rate': 4.4909962899285134e-05, 'epoch': 0.31}
{'loss': 3.3128, 'learning_rate': 4.472144300666606e-05, 'epoch': 0.32}
{'loss': 3.3471, 'learning_rate': 4.4532923114047e-05, 'epoch': 0.33}
{'loss': 3.3371, 'learning_rate': 4.434440322142793e-05, 'epoch': 0.34}
{'loss': 3.3211, 'learning_rate': 4.4155883328808854e-05, 'epoch': 0.35}
{'loss': 3.3106, 'learning_rate': 4.396736343618979e-05, 'epoch': 0.36}
{'loss': 3.2928, 'learning_rate': 4.377884354357072e-05, 'epoch': 0.37}
{'loss': 3.279, 'learning_rate': 4.3590323650951655e-05, 'epoch': 0.38}
{'loss': 3.2732, 'learning_rate': 4.340180375833258e-05, 'epoch': 0.4}
{'loss': 3.2437, 'learning_rate': 4.321328386571351e-05, 'epoch': 0.41}
{'loss': 3.2537, 'learning_rate': 4.302476397309444e-05, 'epoch': 0.42}
{'loss': 3.2595, 'learning_rate': 4.2836244080475376e-05, 'epoch': 0.43}
{'loss': 3.2459, 'learning_rate': 4.26477241878563e-05, 'epoch': 0.44}
{'loss': 3.2097, 'learning_rate': 4.2459204295237236e-05, 'epoch': 0.45}
{'loss': 3.2031, 'learning_rate': 4.227068440261816e-05, 'epoch': 0.46}
{'loss': 3.2146, 'learning_rate': 4.2082164509999096e-05, 'epoch': 0.48}
{'loss': 3.203, 'learning_rate': 4.189364461738003e-05, 'epoch': 0.49}
{'loss': 3.2067, 'learning_rate': 4.170512472476096e-05, 'epoch': 0.5}
{'loss': 3.2143, 'learning_rate': 4.151660483214189e-05, 'epoch': 0.51}
{'loss': 3.1779, 'learning_rate': 4.1328084939522824e-05, 'epoch': 0.52}
{'loss': 3.1974, 'learning_rate': 4.113956504690375e-05, 'epoch': 0.53}
{'loss': 3.1777, 'learning_rate': 4.0951045154284684e-05, 'epoch': 0.54}
{'loss': 3.1839, 'learning_rate': 4.076252526166561e-05, 'epoch': 0.55}
{'loss': 3.1723, 'learning_rate': 4.0574005369046545e-05, 'epoch': 0.57}
{'loss': 3.1805, 'learning_rate': 4.038548547642748e-05, 'epoch': 0.58}
{'loss': 3.1537, 'learning_rate': 4.0196965583808405e-05, 'epoch': 0.59}
{'loss': 3.1595, 'learning_rate': 4.000844569118933e-05, 'epoch': 0.6}
{'loss': 3.1422, 'learning_rate': 3.9819925798570265e-05, 'epoch': 0.61}
{'loss': 3.148, 'learning_rate': 3.96314059059512e-05, 'epoch': 0.62}
{'loss': 3.128, 'learning_rate': 3.944288601333213e-05, 'epoch': 0.63}
{'loss': 3.149, 'learning_rate': 3.925436612071306e-05, 'epoch': 0.64}
{'loss': 3.1238, 'learning_rate': 3.9065846228093986e-05, 'epoch': 0.66}
{'loss': 3.1136, 'learning_rate': 3.8877326335474926e-05, 'epoch': 0.67}
{'loss': 3.1283, 'learning_rate': 3.868880644285585e-05, 'epoch': 0.68}
{'loss': 3.1089, 'learning_rate': 3.850028655023678e-05, 'epoch': 0.69}
{'loss': 3.1145, 'learning_rate': 3.831176665761771e-05, 'epoch': 0.7}
{'loss': 3.1305, 'learning_rate': 3.812324676499865e-05, 'epoch': 0.71}
{'loss': 3.1102, 'learning_rate': 3.793472687237958e-05, 'epoch': 0.72}
{'loss': 3.1088, 'learning_rate': 3.774620697976051e-05, 'epoch': 0.74}
{'loss': 3.1036, 'learning_rate': 3.7557687087141434e-05, 'epoch': 0.75}
{'loss': 3.0917, 'learning_rate': 3.736916719452237e-05, 'epoch': 0.76}
{'loss': 3.0827, 'learning_rate': 3.71806473019033e-05, 'epoch': 0.77}
{'loss': 3.1024, 'learning_rate': 3.699212740928423e-05, 'epoch': 0.78}
{'loss': 3.0986, 'learning_rate': 3.680360751666516e-05, 'epoch': 0.79}
{'loss': 3.0827, 'learning_rate': 3.661508762404609e-05, 'epoch': 0.8}
{'loss': 3.0739, 'learning_rate': 3.642656773142702e-05, 'epoch': 0.81}
{'loss': 3.0742, 'learning_rate': 3.6238047838807955e-05, 'epoch': 0.83}
{'loss': 3.0579, 'learning_rate': 3.604952794618888e-05, 'epoch': 0.84}
{'loss': 3.0552, 'learning_rate': 3.5861008053569816e-05, 'epoch': 0.85}
{'loss': 3.0846, 'learning_rate': 3.567248816095074e-05, 'epoch': 0.86}
{'loss': 3.0402, 'learning_rate': 3.5483968268331676e-05, 'epoch': 0.87}
{'loss': 3.0535, 'learning_rate': 3.529544837571261e-05, 'epoch': 0.88}
{'loss': 3.0621, 'learning_rate': 3.5106928483093536e-05, 'epoch': 0.89}
{'loss': 3.0289, 'learning_rate': 3.491840859047446e-05, 'epoch': 0.9}
{'loss': 3.016, 'learning_rate': 3.4729888697855403e-05, 'epoch': 0.92}
{'loss': 3.0375, 'learning_rate': 3.454136880523633e-05, 'epoch': 0.93}
{'loss': 3.0299, 'learning_rate': 3.4352848912617264e-05, 'epoch': 0.94}
{'loss': 3.0428, 'learning_rate': 3.416432901999819e-05, 'epoch': 0.95}
{'loss': 2.9992, 'learning_rate': 3.3975809127379124e-05, 'epoch': 0.96}
{'loss': 3.0177, 'learning_rate': 3.378728923476006e-05, 'epoch': 0.97}
{'loss': 3.0122, 'learning_rate': 3.3598769342140984e-05, 'epoch': 0.98}
{'loss': 3.0335, 'learning_rate': 3.341024944952191e-05, 'epoch': 1.0}
{'loss': 2.9761, 'learning_rate': 3.3221729556902845e-05, 'epoch': 1.01}
{'loss': 2.9668, 'learning_rate': 3.303320966428378e-05, 'epoch': 1.02}
{'loss': 2.9537, 'learning_rate': 3.2844689771664705e-05, 'epoch': 1.03}
{'loss': 2.9795, 'learning_rate': 3.265616987904564e-05, 'epoch': 1.04}
{'loss': 2.9563, 'learning_rate': 3.2467649986426565e-05, 'epoch': 1.05}
{'loss': 2.9625, 'learning_rate': 3.2279130093807506e-05, 'epoch': 1.06}
{'loss': 3.0096, 'learning_rate': 3.209061020118843e-05, 'epoch': 1.07}
{'loss': 2.9671, 'learning_rate': 3.190209030856936e-05, 'epoch': 1.09}
{'loss': 2.9793, 'learning_rate': 3.171357041595029e-05, 'epoch': 1.1}
{'loss': 2.9848, 'learning_rate': 3.1525050523331226e-05, 'epoch': 1.11}
{'loss': 2.9652, 'learning_rate': 3.133653063071215e-05, 'epoch': 1.12}
{'loss': 2.9725, 'learning_rate': 3.114801073809309e-05, 'epoch': 1.13}
{'loss': 2.9598, 'learning_rate': 3.0959490845474014e-05, 'epoch': 1.14}
{'loss': 2.9552, 'learning_rate': 3.077097095285495e-05, 'epoch': 1.15}
{'loss': 2.9628, 'learning_rate': 3.058245106023588e-05, 'epoch': 1.17}
{'loss': 2.9519, 'learning_rate': 3.0393931167616807e-05, 'epoch': 1.18}
{'loss': 2.9348, 'learning_rate': 3.020541127499774e-05, 'epoch': 1.19}
{'loss': 2.9513, 'learning_rate': 3.001689138237867e-05, 'epoch': 1.2}
{'loss': 2.9178, 'learning_rate': 2.9828371489759598e-05, 'epoch': 1.21}
{'loss': 2.9222, 'learning_rate': 2.9639851597140535e-05, 'epoch': 1.22}
{'loss': 2.9332, 'learning_rate': 2.945133170452146e-05, 'epoch': 1.23}
{'loss': 2.9674, 'learning_rate': 2.9262811811902392e-05, 'epoch': 1.24}
{'loss': 2.9324, 'learning_rate': 2.9074291919283325e-05, 'epoch': 1.26}
{'loss': 2.911, 'learning_rate': 2.8885772026664256e-05, 'epoch': 1.27}
{'loss': 2.9354, 'learning_rate': 2.869725213404519e-05, 'epoch': 1.28}
{'loss': 2.9119, 'learning_rate': 2.8508732241426116e-05, 'epoch': 1.29}
{'loss': 2.9099, 'learning_rate': 2.8320212348807046e-05, 'epoch': 1.3}
{'loss': 2.8734, 'learning_rate': 2.813169245618798e-05, 'epoch': 1.31}
{'loss': 2.9288, 'learning_rate': 2.794317256356891e-05, 'epoch': 1.32}
{'loss': 2.8867, 'learning_rate': 2.7754652670949837e-05, 'epoch': 1.33}
{'loss': 2.9162, 'learning_rate': 2.7566132778330773e-05, 'epoch': 1.35}
{'loss': 2.9132, 'learning_rate': 2.73776128857117e-05, 'epoch': 1.36}
{'loss': 2.8934, 'learning_rate': 2.718909299309263e-05, 'epoch': 1.37}
{'loss': 2.9104, 'learning_rate': 2.7000573100473564e-05, 'epoch': 1.38}
{'loss': 2.8851, 'learning_rate': 2.6812053207854494e-05, 'epoch': 1.39}
{'loss': 2.8792, 'learning_rate': 2.6623533315235428e-05, 'epoch': 1.4}
{'loss': 2.9079, 'learning_rate': 2.6435013422616354e-05, 'epoch': 1.41}
{'loss': 2.9003, 'learning_rate': 2.6246493529997285e-05, 'epoch': 1.43}
{'loss': 2.8743, 'learning_rate': 2.6057973637378218e-05, 'epoch': 1.44}
{'loss': 2.915, 'learning_rate': 2.586945374475915e-05, 'epoch': 1.45}
{'loss': 2.917, 'learning_rate': 2.5680933852140075e-05, 'epoch': 1.46}
{'loss': 2.9057, 'learning_rate': 2.5492413959521012e-05, 'epoch': 1.47}
{'loss': 2.8692, 'learning_rate': 2.530389406690194e-05, 'epoch': 1.48}
{'loss': 2.8895, 'learning_rate': 2.5115374174282872e-05, 'epoch': 1.49}
{'loss': 2.8555, 'learning_rate': 2.4926854281663803e-05, 'epoch': 1.5}
{'loss': 2.8815, 'learning_rate': 2.4738334389044736e-05, 'epoch': 1.52}
{'loss': 2.8856, 'learning_rate': 2.4549814496425663e-05, 'epoch': 1.53}
{'loss': 2.8499, 'learning_rate': 2.4361294603806596e-05, 'epoch': 1.54}
{'loss': 2.8423, 'learning_rate': 2.4172774711187527e-05, 'epoch': 1.55}
{'loss': 2.872, 'learning_rate': 2.3984254818568457e-05, 'epoch': 1.56}
{'loss': 2.8522, 'learning_rate': 2.3795734925949387e-05, 'epoch': 1.57}
{'loss': 2.8606, 'learning_rate': 2.3607215033330317e-05, 'epoch': 1.58}
{'loss': 2.8235, 'learning_rate': 2.341869514071125e-05, 'epoch': 1.59}
{'loss': 2.8521, 'learning_rate': 2.3230175248092177e-05, 'epoch': 1.61}
{'loss': 2.8704, 'learning_rate': 2.304165535547311e-05, 'epoch': 1.62}
{'loss': 2.8913, 'learning_rate': 2.285313546285404e-05, 'epoch': 1.63}
{'loss': 2.8525, 'learning_rate': 2.2664615570234975e-05, 'epoch': 1.64}
{'loss': 2.8432, 'learning_rate': 2.24760956776159e-05, 'epoch': 1.65}
{'loss': 2.8659, 'learning_rate': 2.2287575784996835e-05, 'epoch': 1.66}
{'loss': 2.8612, 'learning_rate': 2.2099055892377765e-05, 'epoch': 1.67}
{'loss': 2.8396, 'learning_rate': 2.1910535999758695e-05, 'epoch': 1.69}
{'loss': 2.844, 'learning_rate': 2.1722016107139626e-05, 'epoch': 1.7}
{'loss': 2.8554, 'learning_rate': 2.1533496214520556e-05, 'epoch': 1.71}
{'loss': 2.8619, 'learning_rate': 2.134497632190149e-05, 'epoch': 1.72}
{'loss': 2.8336, 'learning_rate': 2.115645642928242e-05, 'epoch': 1.73}
{'loss': 2.8267, 'learning_rate': 2.096793653666335e-05, 'epoch': 1.74}
{'loss': 2.8504, 'learning_rate': 2.077941664404428e-05, 'epoch': 1.75}
{'loss': 2.858, 'learning_rate': 2.0590896751425213e-05, 'epoch': 1.76}
{'loss': 2.8273, 'learning_rate': 2.040237685880614e-05, 'epoch': 1.78}
{'loss': 2.8373, 'learning_rate': 2.0213856966187074e-05, 'epoch': 1.79}
{'loss': 2.8511, 'learning_rate': 2.0025337073568004e-05, 'epoch': 1.8}
{'loss': 2.834, 'learning_rate': 1.9836817180948934e-05, 'epoch': 1.81}
{'loss': 2.8324, 'learning_rate': 1.9648297288329864e-05, 'epoch': 1.82}
{'loss': 2.822, 'learning_rate': 1.9459777395710794e-05, 'epoch': 1.83}
{'loss': 2.8228, 'learning_rate': 1.9271257503091728e-05, 'epoch': 1.84}
{'loss': 2.8492, 'learning_rate': 1.9082737610472658e-05, 'epoch': 1.86}
{'loss': 2.8425, 'learning_rate': 1.8894217717853588e-05, 'epoch': 1.87}
{'loss': 2.7752, 'learning_rate': 1.870569782523452e-05, 'epoch': 1.88}
{'loss': 2.7919, 'learning_rate': 1.8517177932615452e-05, 'epoch': 1.89}
{'loss': 2.8426, 'learning_rate': 1.8328658039996382e-05, 'epoch': 1.9}
{'loss': 2.8125, 'learning_rate': 1.8140138147377312e-05, 'epoch': 1.91}
{'loss': 2.8181, 'learning_rate': 1.7951618254758242e-05, 'epoch': 1.92}
{'loss': 2.819, 'learning_rate': 1.7763098362139176e-05, 'epoch': 1.93}
{'loss': 2.8139, 'learning_rate': 1.7574578469520103e-05, 'epoch': 1.95}
{'loss': 2.8107, 'learning_rate': 1.7386058576901036e-05, 'epoch': 1.96}
{'loss': 2.8131, 'learning_rate': 1.7197538684281966e-05, 'epoch': 1.97}
{'loss': 2.8093, 'learning_rate': 1.7009018791662897e-05, 'epoch': 1.98}
{'loss': 2.7991, 'learning_rate': 1.6820498899043827e-05, 'epoch': 1.99}
{'loss': 2.7819, 'learning_rate': 1.6631979006424757e-05, 'epoch': 2.0}
{'loss': 2.803, 'learning_rate': 1.644345911380569e-05, 'epoch': 2.01}
{'loss': 2.7669, 'learning_rate': 1.625493922118662e-05, 'epoch': 2.02}
{'loss': 2.8085, 'learning_rate': 1.606641932856755e-05, 'epoch': 2.04}
{'loss': 2.8126, 'learning_rate': 1.587789943594848e-05, 'epoch': 2.05}
{'loss': 2.7974, 'learning_rate': 1.5689379543329415e-05, 'epoch': 2.06}
{'loss': 2.7797, 'learning_rate': 1.5500859650710345e-05, 'epoch': 2.07}
{'loss': 2.7735, 'learning_rate': 1.5312339758091275e-05, 'epoch': 2.08}
{'loss': 2.8107, 'learning_rate': 1.5123819865472205e-05, 'epoch': 2.09}
{'loss': 2.7931, 'learning_rate': 1.4935299972853137e-05, 'epoch': 2.1}
{'loss': 2.7787, 'learning_rate': 1.4746780080234069e-05, 'epoch': 2.12}
{'loss': 2.7715, 'learning_rate': 1.4558260187614997e-05, 'epoch': 2.13}
{'loss': 2.7831, 'learning_rate': 1.4369740294995929e-05, 'epoch': 2.14}
{'loss': 2.7537, 'learning_rate': 1.4181220402376861e-05, 'epoch': 2.15}
{'loss': 2.7853, 'learning_rate': 1.399270050975779e-05, 'epoch': 2.16}
{'loss': 2.7853, 'learning_rate': 1.3804180617138721e-05, 'epoch': 2.17}
{'loss': 2.7598, 'learning_rate': 1.3615660724519652e-05, 'epoch': 2.18}
{'loss': 2.7856, 'learning_rate': 1.3427140831900583e-05, 'epoch': 2.19}
{'loss': 2.7803, 'learning_rate': 1.3238620939281512e-05, 'epoch': 2.21}
{'loss': 2.7641, 'learning_rate': 1.3050101046662444e-05, 'epoch': 2.22}
{'loss': 2.7542, 'learning_rate': 1.2861581154043376e-05, 'epoch': 2.23}
{'loss': 2.8045, 'learning_rate': 1.2673061261424307e-05, 'epoch': 2.24}
{'loss': 2.7733, 'learning_rate': 1.2484541368805238e-05, 'epoch': 2.25}
{'loss': 2.7646, 'learning_rate': 1.2296021476186168e-05, 'epoch': 2.26}
{'loss': 2.7682, 'learning_rate': 1.21075015835671e-05, 'epoch': 2.27}
{'loss': 2.7673, 'learning_rate': 1.191898169094803e-05, 'epoch': 2.28}
{'loss': 2.765, 'learning_rate': 1.1730461798328962e-05, 'epoch': 2.3}
{'loss': 2.7769, 'learning_rate': 1.1541941905709892e-05, 'epoch': 2.31}
{'loss': 2.756, 'learning_rate': 1.1353422013090822e-05, 'epoch': 2.32}
{'loss': 2.7734, 'learning_rate': 1.1164902120471752e-05, 'epoch': 2.33}
{'loss': 2.7611, 'learning_rate': 1.0976382227852682e-05, 'epoch': 2.34}
{'loss': 2.7699, 'learning_rate': 1.0787862335233614e-05, 'epoch': 2.35}
{'loss': 2.752, 'learning_rate': 1.0599342442614544e-05, 'epoch': 2.36}
{'loss': 2.7571, 'learning_rate': 1.0410822549995476e-05, 'epoch': 2.38}
{'loss': 2.7203, 'learning_rate': 1.0222302657376406e-05, 'epoch': 2.39}
{'loss': 2.7535, 'learning_rate': 1.0033782764757338e-05, 'epoch': 2.4}
{'loss': 2.7665, 'learning_rate': 9.845262872138268e-06, 'epoch': 2.41}
{'loss': 2.7445, 'learning_rate': 9.6567429795192e-06, 'epoch': 2.42}
{'loss': 2.7465, 'learning_rate': 9.46822308690013e-06, 'epoch': 2.43}
{'loss': 2.7657, 'learning_rate': 9.27970319428106e-06, 'epoch': 2.44}
{'loss': 2.7517, 'learning_rate': 9.09118330166199e-06, 'epoch': 2.45}
{'loss': 2.756, 'learning_rate': 8.902663409042923e-06, 'epoch': 2.47}
{'loss': 2.7688, 'learning_rate': 8.714143516423853e-06, 'epoch': 2.48}
{'loss': 2.7378, 'learning_rate': 8.525623623804785e-06, 'epoch': 2.49}
{'loss': 2.7766, 'learning_rate': 8.337103731185715e-06, 'epoch': 2.5}
{'loss': 2.7495, 'learning_rate': 8.148583838566647e-06, 'epoch': 2.51}
{'loss': 2.7418, 'learning_rate': 7.960063945947577e-06, 'epoch': 2.52}
{'loss': 2.7398, 'learning_rate': 7.771544053328507e-06, 'epoch': 2.53}
{'loss': 2.7567, 'learning_rate': 7.583024160709439e-06, 'epoch': 2.55}
{'loss': 2.7444, 'learning_rate': 7.394504268090369e-06, 'epoch': 2.56}
{'loss': 2.7609, 'learning_rate': 7.2059843754713e-06, 'epoch': 2.57}
{'loss': 2.7371, 'learning_rate': 7.01746448285223e-06, 'epoch': 2.58}
{'loss': 2.7545, 'learning_rate': 6.828944590233162e-06, 'epoch': 2.59}
{'loss': 2.7658, 'learning_rate': 6.640424697614092e-06, 'epoch': 2.6}
{'loss': 2.7415, 'learning_rate': 6.451904804995024e-06, 'epoch': 2.61}
{'loss': 2.7152, 'learning_rate': 6.263384912375954e-06, 'epoch': 2.62}
{'loss': 2.7385, 'learning_rate': 6.074865019756884e-06, 'epoch': 2.64}
{'loss': 2.7369, 'learning_rate': 5.886345127137815e-06, 'epoch': 2.65}
{'loss': 2.7381, 'learning_rate': 5.6978252345187464e-06, 'epoch': 2.66}
{'loss': 2.7651, 'learning_rate': 5.5093053418996774e-06, 'epoch': 2.67}
{'loss': 2.724, 'learning_rate': 5.3207854492806085e-06, 'epoch': 2.68}
{'loss': 2.7313, 'learning_rate': 5.1322655566615395e-06, 'epoch': 2.69}
{'loss': 2.7384, 'learning_rate': 4.94374566404247e-06, 'epoch': 2.7}
{'loss': 2.7568, 'learning_rate': 4.755225771423401e-06, 'epoch': 2.71}
{'loss': 2.7507, 'learning_rate': 4.566705878804332e-06, 'epoch': 2.73}
{'loss': 2.734, 'learning_rate': 4.378185986185263e-06, 'epoch': 2.74}
{'loss': 2.734, 'learning_rate': 4.189666093566194e-06, 'epoch': 2.75}
{'loss': 2.7497, 'learning_rate': 4.001146200947124e-06, 'epoch': 2.76}
{'loss': 2.7607, 'learning_rate': 3.8126263083280553e-06, 'epoch': 2.77}
{'loss': 2.7124, 'learning_rate': 3.624106415708986e-06, 'epoch': 2.78}
{'loss': 2.7506, 'learning_rate': 3.435586523089917e-06, 'epoch': 2.79}
{'loss': 2.7465, 'learning_rate': 3.247066630470848e-06, 'epoch': 2.81}
{'loss': 2.752, 'learning_rate': 3.058546737851778e-06, 'epoch': 2.82}
{'loss': 2.7179, 'learning_rate': 2.870026845232709e-06, 'epoch': 2.83}
{'loss': 2.74, 'learning_rate': 2.68150695261364e-06, 'epoch': 2.84}
{'loss': 2.7731, 'learning_rate': 2.4929870599945707e-06, 'epoch': 2.85}
{'loss': 2.7571, 'learning_rate': 2.3044671673755017e-06, 'epoch': 2.86}
{'loss': 2.7256, 'learning_rate': 2.1159472747564323e-06, 'epoch': 2.87}
{'loss': 2.7499, 'learning_rate': 1.9274273821373633e-06, 'epoch': 2.88}
{'loss': 2.725, 'learning_rate': 1.738907489518294e-06, 'epoch': 2.9}
{'loss': 2.7357, 'learning_rate': 1.550387596899225e-06, 'epoch': 2.91}
{'loss': 2.7426, 'learning_rate': 1.3618677042801557e-06, 'epoch': 2.92}
{'loss': 2.7074, 'learning_rate': 1.1733478116610865e-06, 'epoch': 2.93}
{'loss': 2.7608, 'learning_rate': 9.848279190420173e-07, 'epoch': 2.94}
{'loss': 2.7834, 'learning_rate': 7.963080264229481e-07, 'epoch': 2.95}
{'loss': 2.7351, 'learning_rate': 6.07788133803879e-07, 'epoch': 2.96}
{'loss': 2.7238, 'learning_rate': 4.192682411848098e-07, 'epoch': 2.97}
{'loss': 2.7276, 'learning_rate': 2.3074834856574068e-07, 'epoch': 2.99}
{'loss': 2.7421, 'learning_rate': 4.222845594667149e-08, 'epoch': 3.0}
{'train_runtime': 7294.1523, 'train_samples_per_second': 145.444, 'train_steps_per_second': 18.181, 'train_loss': 2.969071506040796, 'epoch': 3.0}
***** train metrics *****
  epoch                    =        3.0
  train_loss               =     2.9691
  train_runtime            = 2:01:34.15
  train_samples            =     353630
  train_samples_per_second =    145.444
  train_steps_per_second   =     18.181
10/17/2022 10:46:26 - INFO - __main__ - *** Evaluate ***
***** eval metrics *****
  epoch                   =        3.0
  eval_accuracy           =     0.0034
  eval_loss               =     2.9648
  eval_runtime            = 1:34:22.71
  eval_samples            =     119828
  eval_samples_per_second =     21.161
  eval_steps_per_second   =      2.645
10/17/2022 12:20:49 - INFO - __main__ - *** Predict ***
***** predict metrics *****
  predict_accuracy           =     0.0033
  predict_loss               =     2.9488
  predict_runtime            = 1:33:49.23
  predict_samples            =     118751
  predict_samples_per_second =     21.095
  predict_steps_per_second   =      2.637
